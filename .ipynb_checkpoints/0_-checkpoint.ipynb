{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e6d6054",
   "metadata": {},
   "source": [
    "# 0. Libs & Creds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02559ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import glob\n",
    "import gc\n",
    "\n",
    "import calendar\n",
    "from datetime import date, timedelta, datetime\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import *\n",
    "# from pyspark.sql.functions import *\n",
    "# from pyspark.sql.functions import udf, struct, count_distinct, from_unixtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ef570c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "s3a = 's3a://pvc-75e6242d-1f96-4903-a9eb-22fa28f5b73e'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6aac8b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/__RAYDTT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/__RAYDTT'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "home_repo = '/home/jovyan'\n",
    "project_repo = f'{home_repo}/__RAYDTT'\n",
    "# svarygin_repo = f'{project_repo}/_SVARYGIN'\n",
    "%cd {project_repo}\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61c47ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: /user/st054552/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"/user/st054552/proxy/4040/jobs/\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f3121746250>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def access_data(file_path):\n",
    "    with open(file_path) as file:\n",
    "        access_data = json.load(file)\n",
    "    return access_data\n",
    "\n",
    "access_s3_data = access_data('.access_s3.json')\n",
    "\n",
    "print('user:', os.environ['JUPYTERHUB_SERVICE_PREFIX'])\n",
    "\n",
    "def uiWebUrl(self):\n",
    "    from urllib.parse import urlparse\n",
    "    web_url = self._jsc.sc().uiWebUrl().get()\n",
    "    port = urlparse(web_url).port\n",
    "    return '{}proxy/{}/jobs/'.format(os.environ['JUPYTERHUB_SERVICE_PREFIX'], port)\n",
    "\n",
    "SparkContext.uiWebUrl = property(uiWebUrl)\n",
    "\n",
    "conf = SparkConf()\n",
    "conf.set('spark.master', 'local[*]')\n",
    "conf.set('spark.driver.memory', '40G')\n",
    "conf.set('spark.driver.maxResultSize', '32G')\n",
    "############################################\n",
    "conf.set('spark.driver.memoryOverhead', '2G')\n",
    "conf.set('spark.executor.memory', '36G') #32G\n",
    "conf.set('spark.executor.memoryOverhead', '2G')\n",
    "conf.set('spark.executor.cores', '10') # 8\n",
    "conf.set('spark.executor.instances', '2')\n",
    "conf.set('spark.dynamicAllocation.enabled', 'true')\n",
    "conf.set('spark.dynamicAllocation.minExecutors', '1')\n",
    "conf.set('spark.dynamicAllocation.maxExecutors', '50')\n",
    "############################################\n",
    "sc = SparkContext(conf=conf)\n",
    "spark = SparkSession(sc)\n",
    "spark._jsc.hadoopConfiguration().set('fs.s3a.access.key', access_s3_data['aws_access_key_id'])\n",
    "spark._jsc.hadoopConfiguration().set('fs.s3a.secret.key', access_s3_data['aws_secret_access_key'])\n",
    "spark._jsc.hadoopConfiguration().set('fs.s3a.impl','org.apache.hadoop.fs.s3a.S3AFileSystem')\n",
    "spark._jsc.hadoopConfiguration().set('fs.s3a.multipart.size', '104857600')\n",
    "spark._jsc.hadoopConfiguration().set('fs.s3a.block.size', '33554432')\n",
    "spark._jsc.hadoopConfiguration().set('fs.s3a.threads.max', '256')\n",
    "spark._jsc.hadoopConfiguration().set('fs.s3a.endpoint', 'http://storage.yandexcloud.net')\n",
    "spark._jsc.hadoopConfiguration().set('fs.s3a.aws.credentials.provider', \n",
    "                                     'org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider')\n",
    "spark\n",
    "\n",
    "# conf.set('spark.driver.memory', '32G')\n",
    "# conf.set('spark.driver.maxResultSize', '4G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dceda383",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4275b8d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vgtest/apr.parquet',\n",
       " 'vgtest/aug.parquet',\n",
       " 'vgtest/dec.parquet',\n",
       " 'vgtest/feb.parquet',\n",
       " 'vgtest/jan.parquet',\n",
       " 'vgtest/jul.parquet',\n",
       " 'vgtest/jun.parquet',\n",
       " 'vgtest/mar.parquet',\n",
       " 'vgtest/may.parquet',\n",
       " 'vgtest/nov.parquet',\n",
       " 'vgtest/oct.parquet',\n",
       " 'vgtest/sep.parquet']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parquets = glob.glob(f'vgtest/*.parquet')\n",
    "parquets.remove('vgtest/data.parquet')\n",
    "parquets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f32d37",
   "metadata": {},
   "source": [
    "# sdf_init & target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7b56fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['amplitude_id', 'event_time', '[server]_purchase', '[server]_subscription_start_date', 'paid']\n",
    "\n",
    "sdf = None\n",
    "\n",
    "for parquet in parquets:\n",
    "    \n",
    "    sdf_temp = spark.read.parquet(parquet).select(columns)\n",
    "    \n",
    "    sdf_temp = (\n",
    "                sdf_temp\n",
    "                #\n",
    "                .selectExpr('*', 'SUBSTRING(`[server]_purchase`[0], 16) AS purchase')\n",
    "                .drop(F.col('`[server]_purchase`'))\n",
    "                #\n",
    "                .selectExpr('*', 'SUBSTRING(`[server]_subscription_start_date`[0], -10) AS subscription_start_date') \\\n",
    "                .withColumn('subscription_start_date', F.col('subscription_start_date').cast('date')) \\\n",
    "                .drop(F.col('`[server]_subscription_start_date`'))\n",
    "                #\n",
    "                .withColumn('event_time', F.col('event_time').cast('date')) \\\n",
    "                .withColumn('paid', F.col('paid').cast('string'))\n",
    "               )\n",
    "                        \n",
    "    if sdf is None:\n",
    "        sdf = sdf_temp\n",
    "    else:\n",
    "        sdf = sdf.unionByName(sdf_temp, allowMissingColumns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a0e707e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- amplitude_id: long (nullable = true)\n",
      " |-- event_time: date (nullable = true)\n",
      " |-- paid: string (nullable = true)\n",
      " |-- purchase: string (nullable = true)\n",
      " |-- subscription_start_date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e79c478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.18 ms, sys: 102 Âµs, total: 4.29 ms\n",
      "Wall time: 129 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "target = (\n",
    "            sdf\n",
    "            .filter(\n",
    "                (F.col('subscription_start_date').isNotNull()) & \n",
    "                ((F.col('paid') == 'yes') | (F.col('paid') == 'true'))\n",
    "                    )\n",
    "            .groupBy('amplitude_id')\n",
    "            .agg(\n",
    "                F.min('subscription_start_date').alias('target_date'),\n",
    "                F.trunc(F.min('subscription_start_date'), 'month').alias('target_month')\n",
    "                )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6e93254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- amplitude_id: long (nullable = true)\n",
      " |-- target_date: date (nullable = true)\n",
      " |-- target_month: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "825fb68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 89.1 ms, sys: 63.2 ms, total: 152 ms\n",
      "Wall time: 15min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "file_path = f'{s3a}/bs_segments/sdf_init.parquet'\n",
    "\n",
    "sdf.write.parquet(path = file_path, mode = 'overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55ad3f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 89.2 ms, sys: 56.7 ms, total: 146 ms\n",
      "Wall time: 14min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "file_path = f'{s3a}/bs_segments/target.parquet'\n",
    "\n",
    "target.write.parquet(path = file_path, mode = 'overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647087bd",
   "metadata": {},
   "source": [
    "# bs_for_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4257949c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bs_for_feb', '2023-01-01', '2023-01-31'),\n",
       " ('bs_for_mar', '2023-02-01', '2023-02-28'),\n",
       " ('bs_for_apr', '2023-03-01', '2023-03-31'),\n",
       " ('bs_for_may', '2023-04-01', '2023-04-30'),\n",
       " ('bs_for_jun', '2023-05-01', '2023-05-31'),\n",
       " ('bs_for_jul', '2023-06-01', '2023-06-30'),\n",
       " ('bs_for_aug', '2023-07-01', '2023-07-31'),\n",
       " ('bs_for_sep', '2023-08-01', '2023-08-31'),\n",
       " ('bs_for_oct', '2023-09-01', '2023-09-30'),\n",
       " ('bs_for_nov', '2023-10-01', '2023-10-31'),\n",
       " ('bs_for_dec', '2023-11-01', '2023-11-30'),\n",
       " ('bs_for_jan', '2023-12-01', '2023-12-31')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year = 2023\n",
    "\n",
    "month_date_ranges = []\n",
    "\n",
    "for month in range(1, 13): \n",
    "    last_day = calendar.monthrange(year, month)[1]\n",
    "    first_date_str = f'{year}-{month:02d}-01'\n",
    "    last_date_str = f'{year}-{month:02d}-{last_day}'\n",
    "    month_date_ranges.append((first_date_str, last_date_str))\n",
    "\n",
    "bs_names = [f'bs_for_{x}' for x in ['feb', 'mar', 'apr', 'may', 'jun', 'jul', \n",
    "                                    'aug', 'sep', 'oct', 'nov', 'dec', 'jan']]\n",
    "\n",
    "month_date_ranges = [(s, a, b) for ((a, b), s) in zip(month_date_ranges, bs_names)]\n",
    "month_date_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a115d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf = spark.read.parquet('bs_segments/sdf_init.parquet')\n",
    "target = spark.read.parquet('bs_segments/target.parquet')\n",
    "\n",
    "sdf.rdd.getNumPartitions(), target.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f16855d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bs_for_feb start time: 08:18:12\n",
      "bs_for_feb finish time: 08:18:19\n",
      "bs_for_mar start time: 08:18:19\n",
      "bs_for_mar finish time: 08:18:21\n",
      "bs_for_apr start time: 08:18:21\n",
      "bs_for_apr finish time: 08:18:23\n",
      "bs_for_may start time: 08:18:23\n",
      "bs_for_may finish time: 08:18:25\n",
      "bs_for_jun start time: 08:18:25\n",
      "bs_for_jun finish time: 08:18:27\n",
      "bs_for_jul start time: 08:18:27\n",
      "bs_for_jul finish time: 08:18:30\n",
      "bs_for_aug start time: 08:18:30\n",
      "bs_for_aug finish time: 08:18:32\n",
      "bs_for_sep start time: 08:18:32\n",
      "bs_for_sep finish time: 08:18:35\n",
      "bs_for_oct start time: 08:18:35\n",
      "bs_for_oct finish time: 08:18:37\n",
      "bs_for_nov start time: 08:18:37\n",
      "bs_for_nov finish time: 08:18:39\n",
      "bs_for_dec start time: 08:18:39\n",
      "bs_for_dec finish time: 08:18:41\n",
      "bs_for_jan start time: 08:18:41\n",
      "bs_for_jan finish time: 08:18:43\n",
      "CPU times: user 426 ms, sys: 38.7 ms, total: 465 ms\n",
      "Wall time: 30.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for bs_name, start_date, end_date in month_date_ranges:\n",
    "    \n",
    "    print(f'{bs_name} start time: {datetime.now().strftime(\"%H:%M:%S\")}')\n",
    "\n",
    "    ids_wo_subs = (\n",
    "                    sdf\n",
    "                    .filter(\n",
    "                            (F.col('event_time') >= F.lit(start_date)) &\n",
    "                            (F.col('event_time') <= F.lit(end_date)) &\n",
    "                             F.col('subscription_start_date').isNull()\n",
    "                            )\n",
    "                    .withColumn('target_month', F.date_add(F.lit(end_date), 1))\n",
    "                   )\n",
    "\n",
    "    excluded_ids = target.filter(F.col('target_date') <= F.lit(end_date)).select('amplitude_id').distinct()\n",
    "\n",
    "    bs = ids_wo_subs.join(\n",
    "                excluded_ids,\n",
    "                ids_wo_subs['amplitude_id'] == excluded_ids['amplitude_id'],\n",
    "                'left_anti'\n",
    "                         ).select('amplitude_id', 'target_month').distinct()\n",
    "    \n",
    "    file_path = f'{s3a}/bs_segments/{bs_name}.parquet'\n",
    "    \n",
    "    bs.write.parquet(path = file_path, mode = 'overwrite')\n",
    "    \n",
    "    del ids_wo_subs, excluded_ids, bs\n",
    "    gc.collect()\n",
    "    \n",
    "    print(f'{bs_name} finish time: {datetime.now().strftime(\"%H:%M:%S\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1edf43",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be0182f",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders_to_remove = [x[0]+'.parquet' for x in month_date_ranges]\n",
    "\n",
    "for folder in folders_to_remove:\n",
    "    !cd bs_segments; rm -rf {folder}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "645542eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\t\t    bs_for_dec.parquet\tbs_for_jun.parquet  bs_for_oct.parquet\n",
      "..\t\t    bs_for_feb.parquet\tbs_for_mar.parquet  bs_for_sep.parquet\n",
      "bs_for_apr.parquet  bs_for_jan.parquet\tbs_for_may.parquet  sdf_init.parquet\n",
      "bs_for_aug.parquet  bs_for_jul.parquet\tbs_for_nov.parquet  target.parquet\n"
     ]
    }
   ],
   "source": [
    "!cd bs_segments; rm -rf bs_for_aug_features_0_test.parquet\n",
    "!cd bs_segments; ls -a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6227a832",
   "metadata": {},
   "source": [
    "# sdf_features_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "129e8f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- $insert_id: string (nullable = true)\n",
      " |-- $insert_key: string (nullable = true)\n",
      " |-- $price: double (nullable = true)\n",
      " |-- $productid: string (nullable = true)\n",
      " |-- $quantity: long (nullable = true)\n",
      " |-- $revenue: double (nullable = true)\n",
      " |-- $revenuetype: string (nullable = true)\n",
      " |-- $schema: string (nullable = true)\n",
      " |-- [server]_currency: string (nullable = true)\n",
      " |-- [server]_purchase: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- [server]_subscription_start_date: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- [server]_total_revenue: double (nullable = true)\n",
      " |-- [server]_trial: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- ab-test: string (nullable = true)\n",
      " |-- action: string (nullable = true)\n",
      " |-- activity: long (nullable = true)\n",
      " |-- adid: string (nullable = true)\n",
      " |-- ads_watched: long (nullable = true)\n",
      " |-- amplitude_attribution_ids: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- amplitude_event_type: string (nullable = true)\n",
      " |-- amplitude_id: long (nullable = true)\n",
      " |-- answer: string (nullable = true)\n",
      " |-- answers: string (nullable = true)\n",
      " |-- answers_right: long (nullable = true)\n",
      " |-- answers_wrong: long (nullable = true)\n",
      " |-- app: long (nullable = true)\n",
      " |-- att_idfa: string (nullable = true)\n",
      " |-- auto_pronunciation: string (nullable = true)\n",
      " |-- chapter: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- client_event_time: string (nullable = true)\n",
      " |-- client_upload_time: string (nullable = true)\n",
      " |-- cohort_day: long (nullable = true)\n",
      " |-- cohort_month: long (nullable = true)\n",
      " |-- cohort_week: long (nullable = true)\n",
      " |-- cohort_year: long (nullable = true)\n",
      " |-- confirm_answers: string (nullable = true)\n",
      " |-- confirm_anwsers: boolean (nullable = true)\n",
      " |-- confirm_quitting_test_toggle: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- data_type: string (nullable = true)\n",
      " |-- day_from_start_showing: long (nullable = true)\n",
      " |-- device_brand: string (nullable = true)\n",
      " |-- device_carrier: string (nullable = true)\n",
      " |-- device_family: string (nullable = true)\n",
      " |-- device_id: string (nullable = true)\n",
      " |-- device_manufacturer: string (nullable = true)\n",
      " |-- device_model: string (nullable = true)\n",
      " |-- device_type: string (nullable = true)\n",
      " |-- dma: string (nullable = true)\n",
      " |-- duration: long (nullable = true)\n",
      " |-- event_id: long (nullable = true)\n",
      " |-- event_time: string (nullable = true)\n",
      " |-- event_type: string (nullable = true)\n",
      " |-- exam_result: long (nullable = true)\n",
      " |-- explain_errors: string (nullable = true)\n",
      " |-- favorites_count: long (nullable = true)\n",
      " |-- free_express_mode: string (nullable = true)\n",
      " |-- from: string (nullable = true)\n",
      " |-- global_user_properties: string (nullable = true)\n",
      " |-- hazard_progress: long (nullable = true)\n",
      " |-- hazard_solved: long (nullable = true)\n",
      " |-- idfa: string (nullable = true)\n",
      " |-- interface_language: string (nullable = true)\n",
      " |-- interface_language_changed: boolean (nullable = true)\n",
      " |-- ip_address: string (nullable = true)\n",
      " |-- is_attribution_event: string (nullable = true)\n",
      " |-- language: string (nullable = true)\n",
      " |-- library: string (nullable = true)\n",
      " |-- lid: string (nullable = true)\n",
      " |-- location_lat: double (nullable = true)\n",
      " |-- location_lng: double (nullable = true)\n",
      " |-- max_daily_streak: long (nullable = true)\n",
      " |-- mistakes: long (nullable = true)\n",
      " |-- mistaps: long (nullable = true)\n",
      " |-- mix_answer_variants: string (nullable = true)\n",
      " |-- mix_answer_variats: boolean (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- next_test: long (nullable = true)\n",
      " |-- orientation: string (nullable = true)\n",
      " |-- os_name: string (nullable = true)\n",
      " |-- os_version: string (nullable = true)\n",
      " |-- paid: string (nullable = true)\n",
      " |-- paired_event_timestamp: double (nullable = true)\n",
      " |-- partner_id: string (nullable = true)\n",
      " |-- path: string (nullable = true)\n",
      " |-- path_started: string (nullable = true)\n",
      " |-- paying: string (nullable = true)\n",
      " |-- percent_solved: double (nullable = true)\n",
      " |-- platform: string (nullable = true)\n",
      " |-- processed_time: string (nullable = true)\n",
      " |-- product: string (nullable = true)\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- productid: string (nullable = true)\n",
      " |-- profile_avatar_change: long (nullable = true)\n",
      " |-- profile_name_change: long (nullable = true)\n",
      " |-- promocode_sd_exam_passed: string (nullable = true)\n",
      " |-- provider: string (nullable = true)\n",
      " |-- purchase_type: string (nullable = true)\n",
      " |-- push_permission: string (nullable = true)\n",
      " |-- query: string (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      " |-- reset_stat_count: long (nullable = true)\n",
      " |-- revenue: double (nullable = true)\n",
      " |-- right_answers: long (nullable = true)\n",
      " |-- rigth_answer_practice: long (nullable = true)\n",
      " |-- sample_rate: string (nullable = true)\n",
      " |-- screen: string (nullable = true)\n",
      " |-- server_received_time: string (nullable = true)\n",
      " |-- server_upload_time: string (nullable = true)\n",
      " |-- session_id: long (nullable = true)\n",
      " |-- show_hint: string (nullable = true)\n",
      " |-- solve_again: long (nullable = true)\n",
      " |-- source_id: string (nullable = true)\n",
      " |-- spent_money: boolean (nullable = true)\n",
      " |-- start_version: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- statistic_deleted: boolean (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- step: long (nullable = true)\n",
      " |-- subscription_after: string (nullable = true)\n",
      " |-- subscription_date_start: string (nullable = true)\n",
      " |-- switched_to: string (nullable = true)\n",
      " |-- time: long (nullable = true)\n",
      " |-- trial: boolean (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- type_of_test: string (nullable = true)\n",
      " |-- user_creation_time: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- user_properties_updated: boolean (nullable = true)\n",
      " |-- uuid: string (nullable = true)\n",
      " |-- version_name: string (nullable = true)\n",
      " |-- video_number: long (nullable = true)\n",
      " |-- voiceover_count: long (nullable = true)\n",
      " |-- was_empty: boolean (nullable = true)\n",
      " |-- writed_to_support: long (nullable = true)\n",
      " |-- wrong_answers: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf_columns = spark.read.parquet('vgtest/aug.parquet')\n",
    "sdf_columns.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f29e5619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sdf_columns.show(2, 100, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2a6b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "city, region, country, currency, device_family, os_name, push_permission\n",
    "\n",
    "agg: event_time / event_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58948422",
   "metadata": {},
   "source": [
    "location_lat\n",
    "location_lng - OK\n",
    "* country - OK\n",
    "* region - OK\n",
    "* interface_language - OK\n",
    "* language - OK\n",
    "* interface_language_changed - OK\n",
    "\n",
    "* trial - OK\n",
    "* push_permission - OK\n",
    "\n",
    "* device_type - OK\n",
    "* device_family - OK\n",
    "* device_carrier - OK\n",
    "* os_name - OK\n",
    "* ip_address - OK\n",
    "* AB-test - OK\n",
    "---------\n",
    "* promocode_sd_exam_passed - OK\n",
    "* AB-test -- OK\n",
    "* ads_watched -- OK\n",
    "* show_hint -- OK\n",
    "* os_name / platform -- OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d5323d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['amplitude_id', 'event_time', 'event_type', 'location_lat', 'location_lng']\n",
    "\n",
    "columns = ['amplitude_id', 'event_time', 'location_lat', 'location_lng', \n",
    "           'city', 'region', 'country', 'currency', 'device_family', 'os_name', 'push_permission']\n",
    "\n",
    "sdf = None\n",
    "\n",
    "for parquet in parquets:\n",
    "    \n",
    "    sdf_temp = spark.read.parquet(parquet).select(columns)\n",
    "    \n",
    "    sdf_temp = (\n",
    "                sdf_temp\n",
    "                #.cast('long'))\n",
    "                .withColumn('event_time', F.col('event_time').cast('timestamp'))\n",
    "                # BETTER !\n",
    "                .withColumn('location_lat', F.coalesce(F.col('location_lat'), F.lit(0)))\n",
    "                .withColumn('location_lng', F.coalesce(F.col('location_lng'), F.lit(0)))\n",
    "               )\n",
    "                        \n",
    "    if sdf is None:\n",
    "        sdf = sdf_temp\n",
    "    else:\n",
    "        sdf = sdf.unionByName(sdf_temp, allowMissingColumns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2c60daaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 63.7 ms, sys: 23.8 ms, total: 87.6 ms\n",
      "Wall time: 9min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "file_path = f'{s3a}/bs_segments/sdf_features_0.parquet'\n",
    "\n",
    "sdf.write.parquet(path = file_path, mode = 'overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2d3f36b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\t\t    bs_for_jan.parquet\tbs_for_oct.parquet\n",
      "..\t\t    bs_for_jul.parquet\tbs_for_sep.parquet\n",
      "bs_for_apr.parquet  bs_for_jun.parquet\tsdf_features_0.parquet\n",
      "bs_for_aug.parquet  bs_for_mar.parquet\tsdf_init.parquet\n",
      "bs_for_dec.parquet  bs_for_may.parquet\ttarget.parquet\n",
      "bs_for_feb.parquet  bs_for_nov.parquet\n"
     ]
    }
   ],
   "source": [
    "!cd bs_segments; ls -a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a51072f",
   "metadata": {},
   "source": [
    "# bs_for_month_features_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71c7784a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bs_for_feb',\n",
       " 'bs_for_mar',\n",
       " 'bs_for_apr',\n",
       " 'bs_for_may',\n",
       " 'bs_for_jun',\n",
       " 'bs_for_jul',\n",
       " 'bs_for_aug',\n",
       " 'bs_for_sep',\n",
       " 'bs_for_oct',\n",
       " 'bs_for_nov',\n",
       " 'bs_for_dec',\n",
       " 'bs_for_jan']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs_for_months = [i[0] for i in month_date_ranges]\n",
    "bs_for_months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "583dabb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('DROP VIEW IF EXISTS bs_for_aug_features_0')\n",
    "spark.sql('DROP VIEW IF EXISTS bs_for_aug')\n",
    "spark.sql('DROP VIEW IF EXISTS sdf')\n",
    "spark.sql('SHOW TABLES').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b84c74b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "|         |      sdf|       true|\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf = spark.read.parquet('bs_segments/sdf_features_0.parquet')\n",
    "sdf.createOrReplaceTempView('sdf')\n",
    "spark.sql('SHOW TABLES').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c1806e",
   "metadata": {},
   "source": [
    "**Comment:** for agg choose an appropriate window period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c5076f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "(\n",
    "WITH \n",
    "\n",
    "bs_0 AS \n",
    "(\n",
    "    SELECT \n",
    "        sdf.*\n",
    "        ,bs.target_month\n",
    "    FROM sdf\n",
    "    INNER JOIN bs\n",
    "        ON bs.amplitude_id = sdf.amplitude_id\n",
    "    WHERE sdf.event_time < bs.target_month\n",
    "),\n",
    "\n",
    "max_event_time AS\n",
    "(\n",
    "    SELECT \n",
    "        amplitude_id\n",
    "        ,MAX(event_time) AS max_event_time\n",
    "    FROM bs_0\n",
    "    GROUP BY amplitude_id\n",
    "),\n",
    "\n",
    "bs_max_event_time AS\n",
    "(\n",
    "    SELECT \n",
    "        bs_0.*\n",
    "        ,ROW_NUMBER() OVER (PARTITION BY bs_0.amplitude_id, bs_0.event_time ORDER BY bs_0.location_lat DESC) AS row_n\n",
    "    FROM bs_0\n",
    "    INNER JOIN max_event_time met\n",
    "        ON bs_0.amplitude_id = met.amplitude_id\n",
    "        AND bs_0.event_time = met.max_event_time\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    *\n",
    "FROM bs_max_event_time\n",
    "WHERE row_n = 1\n",
    "\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3e5f21ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bs_for_feb start time: 22:05:18\n",
      "bs_for_feb finish time: 22:05:29\n",
      "bs_for_mar start time: 22:05:29\n",
      "bs_for_mar finish time: 22:05:39\n",
      "bs_for_apr start time: 22:05:39\n",
      "bs_for_apr finish time: 22:05:50\n",
      "bs_for_may start time: 22:05:50\n",
      "bs_for_may finish time: 22:06:01\n",
      "bs_for_jun start time: 22:06:01\n",
      "bs_for_jun finish time: 22:06:14\n",
      "bs_for_jul start time: 22:06:14\n",
      "bs_for_jul finish time: 22:06:27\n",
      "bs_for_aug start time: 22:06:27\n",
      "bs_for_aug finish time: 22:06:41\n",
      "bs_for_sep start time: 22:06:41\n",
      "bs_for_sep finish time: 22:06:57\n",
      "bs_for_oct start time: 22:06:57\n",
      "bs_for_oct finish time: 22:08:09\n",
      "bs_for_nov start time: 22:08:09\n",
      "bs_for_nov finish time: 22:08:25\n",
      "bs_for_dec start time: 22:08:25\n",
      "bs_for_dec finish time: 22:08:41\n",
      "bs_for_jan start time: 22:08:41\n",
      "bs_for_jan finish time: 22:08:56\n",
      "CPU times: user 434 ms, sys: 10.9 ms, total: 445 ms\n",
      "Wall time: 3min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for bs_for_month in bs_for_months:\n",
    "    \n",
    "    print(f'{bs_for_month} start time: {datetime.now().strftime(\"%H:%M:%S\")}')\n",
    "    \n",
    "    bs = spark.read.parquet(f'bs_segments/{bs_for_month}.parquet')\n",
    "    bs.createOrReplaceTempView('bs')\n",
    "    \n",
    "    bs_for_month_features_0 = spark.sql(query)\n",
    "    \n",
    "    file_path = f'{s3a}/bs_segments/{bs_for_month}_features_0.parquet'\n",
    "\n",
    "    bs_for_month_features_0.write.parquet(path = file_path, mode = 'overwrite')\n",
    "    \n",
    "    spark.sql('DROP VIEW IF EXISTS bs')\n",
    "    del bs, bs_for_month_features_0\n",
    "    gc.collect()\n",
    "     \n",
    "    print(f'{bs_for_month} finish time: {datetime.now().strftime(\"%H:%M:%S\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bd40cbd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39289 39289 True\n",
      "40573 40573 True\n",
      "47453 47453 True\n",
      "50795 50795 True\n",
      "61435 61435 True\n",
      "74258 74258 True\n",
      "82073 82073 True\n",
      "85075 85075 True\n",
      "69362 69362 True\n",
      "64782 64782 True\n",
      "74944 74944 True\n",
      "72779 72779 True\n",
      "CPU times: user 18.6 ms, sys: 35 ms, total: 53.6 ms\n",
      "Wall time: 4.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for bs_for_month in bs_for_months:\n",
    "    bs_for_month = spark.read.parquet(f'bs_segments/{bs_for_month}.parquet')\n",
    "    print(bs_for_month.count(), bs_for_month.select('amplitude_id').distinct().count(), \\\n",
    "          bs_for_month.count() == bs_for_month.select('amplitude_id').distinct().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f3ade1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39289 39289 True\n",
      "40573 40573 True\n",
      "47453 47453 True\n",
      "50795 50795 True\n",
      "61435 61435 True\n",
      "74258 74258 True\n",
      "82073 82073 True\n",
      "85075 85075 True\n",
      "69362 69362 True\n",
      "64782 64782 True\n",
      "74944 74944 True\n",
      "72779 72779 True\n",
      "CPU times: user 29.7 ms, sys: 18.1 ms, total: 47.8 ms\n",
      "Wall time: 5.15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for bs_for_month in bs_for_months:\n",
    "    bs_for_month_features_0 = spark.read.parquet(f'bs_segments/{bs_for_month}_features_0.parquet')\n",
    "    print(bs_for_month_features_0.count(), bs_for_month_features_0.select('amplitude_id').distinct().count(), \\\n",
    "          bs_for_month_features_0.count() == bs_for_month_features_0.select('amplitude_id').distinct().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f8b11e",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64565cb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bs_segments/bs_for_feb_features_0.parquet',\n",
       " 'bs_segments/bs_for_mar_features_0.parquet',\n",
       " 'bs_segments/bs_for_apr_features_0.parquet',\n",
       " 'bs_segments/bs_for_may_features_0.parquet',\n",
       " 'bs_segments/bs_for_jun_features_0.parquet',\n",
       " 'bs_segments/bs_for_jul_features_0.parquet',\n",
       " 'bs_segments/bs_for_aug_features_0.parquet',\n",
       " 'bs_segments/bs_for_sep_features_0.parquet',\n",
       " 'bs_segments/bs_for_oct_features_0.parquet',\n",
       " 'bs_segments/bs_for_nov_features_0.parquet',\n",
       " 'bs_segments/bs_for_dec_features_0.parquet',\n",
       " 'bs_segments/bs_for_jan_features_0.parquet']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parquets = [f'bs_segments/{bs_for_month}_features_0.parquet' for bs_for_month in bs_for_months]\n",
    "parquets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7361c45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.2 ms, sys: 3.75 ms, total: 15 ms\n",
      "Wall time: 3.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sdf = None\n",
    "\n",
    "for parquet in parquets:\n",
    "    \n",
    "    sdf_temp = spark.read.parquet(parquet).drop('row_n')\n",
    "                        \n",
    "    if sdf is None:\n",
    "        sdf = sdf_temp\n",
    "    else:\n",
    "        sdf = sdf.unionByName(sdf_temp, allowMissingColumns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3a5266c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0----------------------------------\n",
      " amplitude_id    | 301945958567            \n",
      " event_time      | 2023-01-09 00:11:54.198 \n",
      " location_lat    | 51.6539                 \n",
      " location_lng    | -0.0888                 \n",
      " city            | Enfield                 \n",
      " region          | Enfield                 \n",
      " country         | United Kingdom          \n",
      " currency        | null                    \n",
      " device_family   | Apple iPhone            \n",
      " os_name         | ios                     \n",
      " push_permission | not_granted             \n",
      " target_month    | 2023-02-01              \n",
      "-RECORD 1----------------------------------\n",
      " amplitude_id    | 302850059008            \n",
      " event_time      | 2023-01-30 08:23:12.592 \n",
      " location_lat    | 0.0                     \n",
      " location_lng    | 0.0                     \n",
      " city            | Manchester              \n",
      " region          | Manchester              \n",
      " country         | United Kingdom          \n",
      " currency        | null                    \n",
      " device_family   | Apple iPhone            \n",
      " os_name         | ios                     \n",
      " push_permission | granted                 \n",
      " target_month    | 2023-02-01              \n",
      "-RECORD 2----------------------------------\n",
      " amplitude_id    | 303500968249            \n",
      " event_time      | 2023-01-07 20:00:22.522 \n",
      " location_lat    | 51.5032                 \n",
      " location_lng    | -0.204                  \n",
      " city            | Feltham                 \n",
      " region          | Hounslow                \n",
      " country         | United Kingdom          \n",
      " currency        | null                    \n",
      " device_family   | Apple iPhone            \n",
      " os_name         | ios                     \n",
      " push_permission | not_granted             \n",
      " target_month    | 2023-02-01              \n",
      "-RECORD 3----------------------------------\n",
      " amplitude_id    | 303884662986            \n",
      " event_time      | 2023-01-26 00:55:16.551 \n",
      " location_lat    | 0.0                     \n",
      " location_lng    | 0.0                     \n",
      " city            | Wolverhampton           \n",
      " region          | Wolverhampton           \n",
      " country         | United Kingdom          \n",
      " currency        | null                    \n",
      " device_family   | Apple iPhone            \n",
      " os_name         | ios                     \n",
      " push_permission | granted                 \n",
      " target_month    | 2023-02-01              \n",
      "-RECORD 4----------------------------------\n",
      " amplitude_id    | 304288130939            \n",
      " event_time      | 2023-01-21 21:35:34.659 \n",
      " location_lat    | 50.8552                 \n",
      " location_lng    | 0.5716                  \n",
      " city            | Littlehampton           \n",
      " region          | West Sussex             \n",
      " country         | United Kingdom          \n",
      " currency        | null                    \n",
      " device_family   | Apple iPhone            \n",
      " os_name         | ios                     \n",
      " push_permission | not_granted             \n",
      " target_month    | 2023-02-01              \n",
      "-RECORD 5----------------------------------\n",
      " amplitude_id    | 304512905394            \n",
      " event_time      | 2023-01-31 20:52:00.654 \n",
      " location_lat    | 0.0                     \n",
      " location_lng    | 0.0                     \n",
      " city            | London                  \n",
      " region          | England                 \n",
      " country         | United Kingdom          \n",
      " currency        | null                    \n",
      " device_family   | Apple iPhone            \n",
      " os_name         | ios                     \n",
      " push_permission | granted                 \n",
      " target_month    | 2023-02-01              \n",
      "-RECORD 6----------------------------------\n",
      " amplitude_id    | 310034535578            \n",
      " event_time      | 2023-01-25 21:07:25.741 \n",
      " location_lat    | 51.5975                 \n",
      " location_lng    | 0.2299                  \n",
      " city            | Chigwell                \n",
      " region          | Essex                   \n",
      " country         | United Kingdom          \n",
      " currency        | null                    \n",
      " device_family   | Apple iPhone            \n",
      " os_name         | ios                     \n",
      " push_permission | granted                 \n",
      " target_month    | 2023-02-01              \n",
      "-RECORD 7----------------------------------\n",
      " amplitude_id    | 310037835483            \n",
      " event_time      | 2023-01-28 20:39:42.519 \n",
      " location_lat    | 51.6524                 \n",
      " location_lng    | -0.2752                 \n",
      " city            | Borehamwood             \n",
      " region          | Hertfordshire           \n",
      " country         | United Kingdom          \n",
      " currency        | null                    \n",
      " device_family   | Apple iPhone            \n",
      " os_name         | ios                     \n",
      " push_permission | not_granted             \n",
      " target_month    | 2023-02-01              \n",
      "-RECORD 8----------------------------------\n",
      " amplitude_id    | 310309253950            \n",
      " event_time      | 2023-01-09 16:50:47.951 \n",
      " location_lat    | 0.0                     \n",
      " location_lng    | 0.0                     \n",
      " city            | London                  \n",
      " region          | England                 \n",
      " country         | United Kingdom          \n",
      " currency        | null                    \n",
      " device_family   | Apple iPhone            \n",
      " os_name         | ios                     \n",
      " push_permission | not_granted             \n",
      " target_month    | 2023-02-01              \n",
      "-RECORD 9----------------------------------\n",
      " amplitude_id    | 311183421336            \n",
      " event_time      | 2023-01-26 17:50:48.519 \n",
      " location_lat    | 52.0361                 \n",
      " location_lng    | -0.7006                 \n",
      " city            | Milton Keynes           \n",
      " region          | Milton Keynes           \n",
      " country         | United Kingdom          \n",
      " currency        | null                    \n",
      " device_family   | Apple iPhone            \n",
      " os_name         | ios                     \n",
      " push_permission | granted                 \n",
      " target_month    | 2023-02-01              \n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.show(10, 100, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6958658e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "762818"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "894c5808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- amplitude_id: long (nullable = true)\n",
      " |-- event_time: timestamp (nullable = true)\n",
      " |-- location_lat: double (nullable = true)\n",
      " |-- location_lng: double (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- device_family: string (nullable = true)\n",
      " |-- os_name: string (nullable = true)\n",
      " |-- push_permission: string (nullable = true)\n",
      " |-- target_month: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b89be35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- amplitude_id_target: long (nullable = true)\n",
      " |-- target_date: date (nullable = true)\n",
      " |-- target_month_target: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target = spark.read.parquet('bs_segments/target.parquet')\n",
    "target = target.withColumnRenamed('amplitude_id', 'amplitude_id_target')\n",
    "target = target.withColumnRenamed('target_month', 'target_month_target')\n",
    "target.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "773b3741",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_w_target = sdf.join(\n",
    "                    target,\n",
    "                    (sdf.amplitude_id == target.amplitude_id_target) & (sdf.target_month == target.target_month_target),\n",
    "                    'left').drop('amplitude_id_target', 'target_month_target')\n",
    "\n",
    "sdf_w_target = sdf_w_target.withColumn('target', F.when(F.col('target_date').isNull(), 0).otherwise(1))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "464b5783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- amplitude_id: long (nullable = true)\n",
      " |-- event_time: timestamp (nullable = true)\n",
      " |-- location_lat: double (nullable = true)\n",
      " |-- location_lng: double (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- device_family: string (nullable = true)\n",
      " |-- os_name: string (nullable = true)\n",
      " |-- push_permission: string (nullable = true)\n",
      " |-- target_month: date (nullable = true)\n",
      " |-- target_date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf_w_target.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "054600ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "762818"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf_w_target.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "638670ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+----------+--------------------+\n",
      "|target_month|count|sum_target|      average_target|\n",
      "+------------+-----+----------+--------------------+\n",
      "|  2023-02-01|39289|       148|0.003766957672631...|\n",
      "|  2023-03-01|40573|       198|0.004880092672466911|\n",
      "|  2023-04-01|47453|       220|0.004636166311929699|\n",
      "|  2023-05-01|50795|       260|0.005118614036814647|\n",
      "|  2023-06-01|61435|       337|  0.0054854724505575|\n",
      "|  2023-07-01|74258|       557|0.007500875326564141|\n",
      "|  2023-08-01|82073|       515|0.006274901611979579|\n",
      "|  2023-09-01|85075|       495|0.005818395533352924|\n",
      "|  2023-10-01|69362|       302|0.004353969032034...|\n",
      "|  2023-11-01|64782|       322|0.004970516501497329|\n",
      "|  2023-12-01|74944|       424|0.005657557643040...|\n",
      "|  2024-01-01|72779|         0|                 0.0|\n",
      "+------------+-----+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_df = sdf_w_target.groupBy(\"target_month\") \\\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"count\"),  # Counts all rows in each group\n",
    "        F.sum(\"target\").alias(\"sum_target\"),  # Sums up the 'target' column values per group\n",
    "        # Calculate the sum of target divided by the count of rows\n",
    "        (F.sum(\"target\") / F.count(\"*\")).alias(\"average_target\")\n",
    "    )\n",
    "result_df.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c2ac0a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+--------------------+\n",
      "| count|sum_target|      average_target|\n",
      "+------+----------+--------------------+\n",
      "|762818|      3778|0.004952688583646...|\n",
      "+------+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_df = sdf_w_target \\\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"count\"),  # Counts all rows in each group\n",
    "        F.sum(\"target\").alias(\"sum_target\"),  # Sums up the 'target' column values per group\n",
    "        # Calculate the sum of target divided by the count of rows\n",
    "        (F.sum(\"target\") / F.count(\"*\")).alias(\"average_target\")\n",
    "    )\n",
    "result_df.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d14360a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8, 0.2, 0.25, 0.3, 0.015)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio_of_ones_in_train_sampled = 0.3\n",
    "ratio_of_ones_in_test_sampled = 0.015\n",
    "\n",
    "test_part = 0.2\n",
    "train_part = 1 - test_part\n",
    "test_to_train = test_part / train_part\n",
    "\n",
    "train_part, test_part, test_to_train, ratio_of_ones_in_train_sampled, ratio_of_ones_in_test_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a89e03d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = sdf_w_target.randomSplit([train_part, test_part], seed = SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88174c9",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12442ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011659943470267008"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sampled_count_1 = train.filter(F.col('target') == 1).count()\n",
    "train_sampled_count = train_sampled_count_1 / ratio_of_ones_in_train_sampled\n",
    "train_sampled_count_0 = train_sampled_count - train_sampled_count_1\n",
    "train_fractions_0 = train_sampled_count_0 / train.filter(F.col('target') == 0).count()\n",
    "train_fractions_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7bbe01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fractions = {0 : train_fractions_0, 1 : 1} # different fractions\n",
    "train_sampled = train.sampleBy(col = 'target', fractions = train_fractions, seed = SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51ba21c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10116, 7081, 3035, 3035)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sampled.count(),\\\n",
    "train_sampled.filter(F.col('target') == 0).count(),\\\n",
    "train_sampled.filter(F.col('target') == 1).count(),\\\n",
    "train_sampled_count_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "87c6a484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+------------------+\n",
      "|count|sum_target|    average_target|\n",
      "+-----+----------+------------------+\n",
      "|10116|      3035|0.3000197706603401|\n",
      "+-----+----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_df = train_sampled \\\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"count\"),  # Counts all rows in each group\n",
    "        F.sum(\"target\").alias(\"sum_target\"),  # Sums up the 'target' column values per group\n",
    "        # Calculate the sum of target divided by the count of rows\n",
    "        (F.sum(\"target\") / F.count(\"*\")).alias(\"average_target\")\n",
    "    )\n",
    "result_df.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5fd5293a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = f'bs_segments/train_sampled.csv'\n",
    "\n",
    "train_sampled.toPandas().to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "edb14217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10116, 14)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = f'bs_segments/train_sampled.csv'\n",
    "train_sampled = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80b943a",
   "metadata": {},
   "source": [
    "# Test sampled too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49489b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sampled_count = train_sampled.count() * test_to_train\n",
    "test_sampled_count_1 = test_sampled_count * ratio_of_ones_in_test_sampled\n",
    "test_sampled_count_0 = test_sampled_count * (1 - ratio_of_ones_in_test_sampled)\n",
    "test_fractions_0 = test_sampled_count_0 / test.filter(F.col('target') == 0).count()\n",
    "test_fractions_1 = test_sampled_count_1 / test.filter(F.col('target') == 1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a0f1e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fractions = {0 : test_fractions_0, 1 : test_fractions_1} # different fractions\n",
    "test_sampled = test.sampleBy(col = 'target', fractions = test_fractions, seed = SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5ea6378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2530, 2529.0, 2493, 37)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sampled.count(),\\\n",
    "test_sampled_count,\\\n",
    "test_sampled.filter(F.col('target') == 0).count(),\\\n",
    "test_sampled.filter(F.col('target') == 1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c4da163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+--------------------+\n",
      "|count|sum_target|      average_target|\n",
      "+-----+----------+--------------------+\n",
      "| 2530|        37|0.014624505928853756|\n",
      "+-----+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_df = test_sampled \\\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"count\"),  # Counts all rows in each group\n",
    "        F.sum(\"target\").alias(\"sum_target\"),  # Sums up the 'target' column values per group\n",
    "        # Calculate the sum of target divided by the count of rows\n",
    "        (F.sum(\"target\") / F.count(\"*\")).alias(\"average_target\")\n",
    "    )\n",
    "result_df.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "aaa3498c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = f'{s3a}/bs_segments/test_sampled.csv'\n",
    "# test_sampled.write.csv(path = file_path, mode = 'overwrite')\n",
    "\n",
    "file_path = f'bs_segments/test_sampled.csv'\n",
    "\n",
    "test_sampled.toPandas().to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8593f29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = f'bs_segments/test_sampled.csv'\n",
    "test_sampled = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd75f7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd8ad80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd80e81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "433a57c4",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "28eb8fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.016590895672196966"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sampled_count = train_sampled.count() * test_to_train\n",
    "test_fraction = test_sampled_count / test.count()\n",
    "test_fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "12163797",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fractions = {0 : test_fraction, 1 : test_fraction} # same fractions\n",
    "test_sampled = test.sampleBy(col = 'target', fractions = test_fractions, seed = SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "3262e592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2527, 2529.0, 2517, 10)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sampled.count(),\\\n",
    "test_sampled_count,\\\n",
    "test_sampled.filter(F.col('target') == 0).count(),\\\n",
    "test_sampled.filter(F.col('target') == 1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "c14df410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+--------------------+\n",
      "|count|sum_target|      average_target|\n",
      "+-----+----------+--------------------+\n",
      "| 2527|        10|0.003957261574990107|\n",
      "+-----+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_df = test_sampled \\\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"count\"),  # Counts all rows in each group\n",
    "        F.sum(\"target\").alias(\"sum_target\"),  # Sums up the 'target' column values per group\n",
    "        # Calculate the sum of target divided by the count of rows\n",
    "        (F.sum(\"target\") / F.count(\"*\")).alias(\"average_target\")\n",
    "    )\n",
    "result_df.show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49ff4ca",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf7adfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddb91f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2443bb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c3b11f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab8c8cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f00cedfb",
   "metadata": {},
   "source": [
    "### Target:\n",
    "\n",
    "**1. Target as `Weekly` / `Monthly` only with `subscription_start_date`**\n",
    "* unified book with LEFT JOIN and NULL further\n",
    "\n",
    "**2. Target as `Weekly` / `Monthly` / `Lifetime`**\n",
    "* LAG() approach\n",
    "* event_time - technically\n",
    "\n",
    "### Questions\n",
    "\n",
    "- ÑÐ¾Ð»ÑÐºÐ¾ Ð±ÐµÐ· Ð¿Ð¾Ð´Ð¿Ð¸ÑÐºÐ¸ Ð¸Ð»Ð¸ ÐºÐ°Ðº - ÑÑÐ»Ð¾Ð²Ð¸Ñ Ð±Ð°Ð·Ð¾Ð²Ð¾Ð³Ð¾ ÑÐµÐ³Ð¼ÐµÐ½ÑÐ° - Ð½Ð° ÑÐºÐ¾Ð»ÑÐºÐ¾ Ð½Ð¾Ð²ÑÑ Ñ ÐºÐ°ÐºÐ¾Ð¹ Ð³Ð»ÑÐ±Ð¸Ð½Ð¾Ð¹\n",
    "- paid - Ð¾Ð±ÑÐ·Ð°ÑÐµÐ»ÑÐ½Ð¾?\n",
    "\n",
    "### Answers\n",
    "- ÑÑÐ°Ð²Ð½Ð¸ÑÑ `MIN(event_time)` Ð¸ Ð¿ÐµÑÐ²Ð¾Ðµ Ð¿Ð¾ÑÐ»Ð²Ð½Ð¸Ðµ `subscription_start_date` - OK\n",
    "- `paid` c `Lifetime`\n",
    "* **paid values:**\n",
    "sdf.select('paid').distinct().show() = `null, false, true, no, yes`\n",
    "* `sdf.filter((F.col('purchase') == 'Lifetime') & (F.col('subscription_start_date').isNotNull())).count()`\n",
    "= **15737** / 74195551 = 0.2 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a9f240",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
